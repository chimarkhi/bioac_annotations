Raven Pro
| Column Name             | Description                                                                 |
|--------------------------|-----------------------------------------------------------------------------|
| `Selection`              | Unique identifier for each annotation                                       |
| `View`                   | Page/view number (if the file is split into multiple views)                 |
| `Channel`                | Audio channel (1 = mono, 1 or 2 = stereo)                                   |
| `Begin Time (s)`         | Start time of the selection in seconds                                      |
| `End Time (s)`           | End time of the selection in seconds                                        |
| `Low Freq (Hz)`          | Lowest frequency of the selection in Hz                                     |
| `High Freq (Hz)`         | Highest frequency of the selection in Hz                                    |
| `Delta Time (s)`         | Duration (End Time - Begin Time)                                            |
| `Delta Freq (Hz)`        | Frequency range (High Freq - Low Freq)                                      |
| `Average Power (dB)`     | Average power level of the selection in decibels (optional)                 |
| `Max Power (dB)`         | Maximum power in the selection (optional)                                   |
| `Peak Power (dB)`        | Frequency with the highest power (optional)                                 |
| `Begin File`             | Audio file name where the selection appears                                 |
| `Annotation` (custom)    | User-added description, e.g., species ID, call type                         |
	Annotation: free form use json
	Others: Bandwidth, peak freq etc

Kaleidoscope:
| Column Name               | Description                                                                 |
|---------------------------|-----------------------------------------------------------------------------|
| `File Name`               | Name of the audio file where detection occurred                             |
| `Start Time (s)`          | Time (in seconds) where the detected sound begins                           |
| `End Time (s)`            | Time (in seconds) where the detected sound ends                             |
| `Low Frequency (kHz)`     | Lowest frequency of the detected sound                                      |
| `High Frequency (kHz)`    | Highest frequency of the detected sound                                     |
| `Delta Frequency (kHz)`   | Frequency range = High - Low                                                |
| `Delta Time (s)`          | Duration of the detection = End - Start                                     |
| `Peak Frequency (kHz)`    | Frequency with the highest energy                                            |
| `Classification`          | Species or group label assigned (if classifier used)                        |
| `Annotation`              | Manual or user-added notes                                                  |
| `Cluster Name` (optional) | Cluster label (for unsupervised clustering)                                 |
| `File Path`               | Full file path to the source audio                                          |
	Annotation: free form use json

Whombat:
id: Unique identifier for the annotation.
audio_id: Reference to the associated audio file.
start_time and end_time: Temporal boundaries of the annotated event (in seconds).
low_freq and high_freq: Frequency range of the event (in Hz).
tags: List of labels, each containing:
    species: Scientific name of the identified species.
    call_type: Type of call (e.g., song, chip, trill).
    confidence: Confidence level of the identification (range: 0.0 to 1.0).
notes: Optional field for additional comments or observations.​
	
	tags: used for annotations; notes for 
	Hierarchical Labeling: in the tags
	

ELAN:
xml based parent - child heirarchial annotation
great for overlapping calls


Audacity:
Start time (in seconds)
End time (in seconds)
Label text (free-form text)

txt file, doesnt support freq annotation, structured metadata, heirarchical or multi field annotations. Needs to be done through custom formattting

Praat:
A TextGrid file in Praat consists of one or more tiers, each containing annotations aligned to specific time intervals. For annotating multiple overlapping species with associated call types and confidence levels, you can design the TextGrid with the following tiers:​
Species Tier: An IntervalTier where each interval represents a detected species vocalization.​
University at Buffalo+2textgridtools.readthedocs.io+2fon.hum.uva.nl+2
Call Type Tier: An IntervalTier aligned with the Species Tier, specifying the type of call (e.g., song, chip).​
Confidence Tier: An IntervalTier aligned with the Species Tier, indicating the confidence level of the annotation.​

By aligning intervals across these tiers, you can represent complex annotations involving multiple overlapping species.
Lot of repetetion of effort for each new attribute, does not natively support freq annotation
Can be parsed using python libs


Biosounds:

